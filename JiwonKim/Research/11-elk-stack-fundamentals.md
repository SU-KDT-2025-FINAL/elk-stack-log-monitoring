# 1.1 ELK 스택 핵심 개념

## 개요

이 문서는 ELK 스택의 핵심 구성 요소인 Elasticsearch, Logstash, Kibana의 기본 개념과 중앙집중식 로깅 시스템의 원리를 다룹니다. 분산 시스템에서의 로그 관리 필요성부터 ELK 스택이 제공하는 솔루션까지 체계적으로 학습할 수 있습니다.

## ELK 스택 개요

### 구성 요소별 역할

#### Elasticsearch
**정의**: 분산형 RESTful 검색 및 분석 엔진

**핵심 특징**:
- **JSON 기반 문서 저장**: 모든 데이터를 JSON 문서 형태로 저장
- **분산 아키텍처**: 여러 노드에 걸쳐 데이터를 분산 저장
- **실시간 검색**: 거의 실시간으로 데이터 검색 및 분석 가능
- **RESTful API**: HTTP 기반의 직관적인 API 제공

**주요 기능**:
- 역색인(Inverted Index)을 통한 빠른 전문 검색
- 집계(Aggregation) 기능으로 데이터 분석
- 자동 샤딩과 복제를 통한 고가용성
- 클러스터 자동 복구 및 리밸런싱

#### Logstash
**정의**: 서버 측 데이터 처리 파이프라인

**파이프라인 구조**:
```
INPUT → FILTER → OUTPUT
  ↓       ↓        ↓
수집    변환     전송
```

**핵심 특징**:
- **플러그인 기반 아키텍처**: 200개 이상의 플러그인 지원
- **실시간 데이터 처리**: 스트리밍 방식으로 데이터 처리
- **다양한 데이터 소스 지원**: 파일, DB, 메시지 큐 등
- **데이터 변환 및 보강**: 구조화되지 않은 데이터를 구조화

**처리 단계별 역할**:
- **Input**: 다양한 소스에서 데이터 수집
- **Filter**: 데이터 파싱, 변환, 필터링
- **Output**: 처리된 데이터를 대상 시스템으로 전송

#### Kibana
**정의**: Elasticsearch 데이터 시각화 및 관리 플랫폼

**핵심 특징**:
- **대화형 시각화**: 실시간 차트 및 그래프 생성
- **대시보드 구성**: 여러 시각화를 조합한 종합 대시보드
- **검색 인터페이스**: 직관적인 데이터 검색 및 필터링
- **관리 도구**: Elasticsearch 클러스터 모니터링 및 관리

**주요 기능**:
- Discover: 데이터 탐색 및 검색
- Visualize: 다양한 형태의 시각화 생성
- Dashboard: 시각화 조합 및 관리
- Dev Tools: Elasticsearch API 직접 실행

## 데이터 흐름 아키텍처

### 전체 데이터 처리 흐름

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  로그 소스   │ →  │  Logstash   │ →  │Elasticsearch│ →  │   Kibana    │
│             │    │             │    │             │    │             │
│ ∙ 웹 서버    │    │ ∙ 데이터 수집│    │ ∙ 인덱싱    │    │ ∙ 시각화    │
│ ∙ 앱 로그    │    │ ∙ 파싱/변환 │    │ ∙ 저장      │    │ ∙ 대시보드  │
│ ∙ 시스템     │    │ ∙ 필터링    │    │ ∙ 검색      │    │ ∙ 분석      │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
```

### 단계별 데이터 처리

#### 1단계: 데이터 수집 (Collection)
**소스 유형**:
- **애플리케이션 로그**: 서비스별 비즈니스 로직 로그
- **웹 서버 로그**: Nginx, Apache 액세스 로그
- **시스템 로그**: OS 레벨 시스템 이벤트
- **데이터베이스 로그**: 쿼리 실행 및 성능 로그

#### 2단계: 데이터 처리 (Processing)
**변환 작업**:
- **파싱**: 비구조화 텍스트를 구조화된 필드로 변환
- **필터링**: 불필요한 데이터 제거 및 중요 데이터 추출
- **보강**: 추가 정보나 메타데이터 추가
- **정규화**: 일관된 포맷으로 데이터 표준화

#### 3단계: 데이터 저장 (Storage)
**인덱싱 과정**:
- **문서 생성**: JSON 형태로 데이터 구조화
- **매핑 적용**: 필드 타입 및 분석 방법 정의
- **샤드 분배**: 여러 노드에 데이터 분산 저장
- **복제본 생성**: 데이터 안정성을 위한 복사본 생성

#### 4단계: 데이터 활용 (Utilization)
**분석 방법**:
- **검색**: 키워드 기반 로그 검색
- **집계**: 통계 정보 및 메트릭 계산
- **시각화**: 차트, 그래프를 통한 데이터 표현
- **알림**: 조건 기반 자동 알림 생성

## 로그 관리 기초

### 기존 로깅 방식의 한계

#### 분산 로깅의 문제점
- **관리 복잡성**: 여러 서버의 개별 로그 파일 관리
- **일관성 부족**: 서버마다 다른 로그 포맷 및 저장 방식
- **검색 어려움**: 여러 파일에 걸친 로그 검색의 비효율성
- **상관관계 분석 제한**: 분산된 로그 간 연관성 파악 곤란

#### 확장성 문제
- **저장 공간**: 각 서버별 디스크 용량 제한
- **성능 저하**: 로그 파일 크기 증가에 따른 검색 성능 저하
- **백업 복잡성**: 여러 위치의 로그 파일 백업 관리

### 중앙집중식 로깅의 이점

#### 운영 효율성
- **통합 관리**: 모든 로그를 단일 시스템에서 관리
- **표준화**: 일관된 로그 포맷 및 메타데이터
- **자동화**: 로그 수집, 처리, 저장의 자동화
- **확장성**: 수평적 확장을 통한 대용량 처리

#### 분석 능력 향상
- **실시간 분석**: 로그 생성과 동시에 분석 가능
- **상관관계 분석**: 여러 시스템 간 로그 연관성 분석
- **패턴 인식**: 기계학습을 통한 이상 패턴 감지
- **예측 분석**: 과거 데이터 기반 미래 예측

### 로그 레벨과 구조화

#### 표준 로그 레벨
```
FATAL  (0) - 애플리케이션 중단을 야기하는 심각한 오류
ERROR  (1) - 기능 실행 실패하지만 애플리케이션 계속 실행
WARN   (2) - 잠재적 문제 상황이지만 정상 동작
INFO   (3) - 일반적인 정보성 메시지
DEBUG  (4) - 개발자를 위한 디버깅 정보
TRACE  (5) - 가장 상세한 실행 흐름 정보
```

#### 구조화된 로깅

**JSON 형태의 로그 예제**:
```json
{
  "@timestamp": "2024-01-15T10:30:00.000Z",
  "level": "ERROR",
  "service": "user-authentication",
  "message": "Failed to authenticate user",
  "context": {
    "user_id": "12345",
    "ip_address": "192.168.1.100",
    "user_agent": "Mozilla/5.0...",
    "error_code": "AUTH_001",
    "response_time_ms": 1250
  },
  "stack_trace": "java.lang.Exception: Invalid credentials..."
}
```

**구조화된 로깅의 장점**:
- **검색 효율성**: 필드별 정확한 검색 가능
- **집계 용이성**: 숫자 필드 기반 통계 계산
- **자동 파싱**: 추가 파싱 없이 즉시 활용 가능
- **일관성**: 표준화된 필드 구조

### 실시간 vs 배치 처리

#### 실시간 처리 (Stream Processing)
**특징**:
- 데이터 생성 즉시 처리 및 분석
- 지연 시간 최소화 (보통 초 단위)
- 지속적인 리소스 사용

**장점**:
- 즉각적인 알림 및 대응 가능
- 실시간 모니터링 및 대시보드 제공
- 시간에 민감한 비즈니스 의사결정 지원

**단점**:
- 높은 리소스 사용량
- 복잡한 시스템 아키텍처
- 데이터 정합성 보장 어려움

**적용 사례**:
- 보안 이벤트 실시간 감지
- 시스템 성능 모니터링
- 사용자 행동 분석

#### 배치 처리 (Batch Processing)
**특징**:
- 일정 시간 간격으로 대량 데이터 처리
- 높은 처리량 (throughput) 지향
- 정해진 시간에 리소스 집중 사용

**장점**:
- 효율적인 리소스 활용
- 안정적이고 예측 가능한 처리
- 복잡한 데이터 변환 및 계산 용이

**단점**:
- 지연 시간 발생 (분~시간 단위)
- 실시간 대응 어려움
- 저장 공간 요구량 높음

**적용 사례**:
- 일일/월별 보고서 생성
- 대용량 데이터 ETL 작업
- 머신러닝 모델 학습

### 확장성 고려사항

#### 데이터 볼륨 관리
**예상 데이터량 계산**:
```
일일 로그량 = 서버 수 × 평균 TPS × 86,400초 × 평균 로그 크기
예: 10대 × 100 TPS × 86,400 × 1KB = 86.4GB/일
```

**보존 정책**:
- **Hot 데이터**: 최근 7일, 빠른 검색 필요
- **Warm 데이터**: 최근 30일, 일반적인 분석 용도
- **Cold 데이터**: 30일~1년, 규정 준수 목적
- **Delete**: 1년 이후 삭제

#### 성능 최적화 전략
**하드웨어 고려사항**:
- **CPU**: 데이터 처리 및 집계 작업
- **메모리**: 검색 성능 및 캐싱
- **디스크**: SSD 권장, 빠른 I/O 성능
- **네트워크**: 노드 간 통신 대역폭

**소프트웨어 최적화**:
- **인덱스 설계**: 적절한 샤드 수 및 복제본 설정
- **매핑 최적화**: 불필요한 필드 인덱싱 제외
- **쿼리 최적화**: 효율적인 검색 쿼리 작성
- **리소스 모니터링**: JVM 힙 메모리 및 GC 튜닝

## 핵심 개념 정리

### Elasticsearch 핵심 용어

| 용어 | 설명 | 예시 |
|------|------|------|
| **클러스터** | 하나 이상의 노드로 구성된 Elasticsearch 인스턴스 집합 | production-cluster |
| **노드** | 클러스터의 개별 Elasticsearch 인스턴스 | node-1, node-2 |
| **인덱스** | 유사한 특성을 가진 문서들의 집합 | logs-nginx-2024.01.15 |
| **타입** | 인덱스 내 문서의 논리적 분류 (7.x부터 deprecated) | _doc |
| **문서** | 인덱싱되는 기본 정보 단위 (JSON) | 개별 로그 엔트리 |
| **필드** | 문서 내 개별 데이터 항목 | timestamp, level, message |
| **샤드** | 인덱스를 물리적으로 분할한 단위 | primary shard, replica shard |

### 로그 관리 모범 사례

#### 로그 설계 원칙
- **구조화**: JSON 형태의 일관된 구조 사용
- **풍부한 컨텍스트**: 문제 해결에 필요한 충분한 정보 포함
- **표준화**: 팀 전체가 합의한 필드명 및 포맷 사용
- **성능 고려**: 과도한 로깅으로 인한 성능 저하 방지

#### 보안 고려사항
- **민감 정보 제거**: 개인정보, 비밀번호 등 로깅 금지
- **접근 제어**: 로그 데이터에 대한 적절한 권한 관리
- **암호화**: 전송 및 저장 시 데이터 암호화
- **감사 로그**: 로그 시스템 자체에 대한 접근 기록

## 다음 단계

이 단계를 완료한 후에는 다음 학습 목표로 진행합니다:
- **Docker 환경 설정**: ELK 스택의 실제 구축 및 설정
- **실습 환경 구성**: 로컬 개발 환경에서 ELK 스택 실행
- **기본 데이터 파이프라인**: 간단한 로그 수집 및 시각화 구현

---

이 문서를 통해 ELK 스택의 핵심 개념과 중앙집중식 로깅의 기본 원리를 이해했다면, 다음 단계인 실제 환경 구축으로 진행할 준비가 되었습니다.